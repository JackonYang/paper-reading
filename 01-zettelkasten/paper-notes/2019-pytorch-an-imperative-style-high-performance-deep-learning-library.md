---
title: PyTorch - An Imperative Style, High-Performance Deep Learning Library
authors:
- Adam Paszke
- S. Gross
- Francisco Massa
- Adam Lerer
- James Bradbury
- Gregory Chanan
- Trevor Killeen
- Zeming Lin
- N. Gimelshein
- L. Antiga
- Alban Desmaison
- "Andreas K\xF6pf"
- E. Yang
- Zach DeVito
- Martin Raison
- Alykhan Tejani
- Sasank Chilamkurthy
- Benoit Steiner
- Lu Fang
- Junjie Bai
- Soumith Chintala
fieldsOfStudy:
- Computer Science
meta_key: 2019-pytorch-an-imperative-style-high-performance-deep-learning-library
numCitedBy: 13996
reading_status: TBD
ref_count: 34
tags:
- gen-from-ref
- other-default
- paper
urls:
- https://www.semanticscholar.org/paper/PyTorch:-An-Imperative-Style,-High-Performance-Deep-Paszke-Gross/3c8a456509e6c0805354bd40a35e3f2dbf8069b1?sort=total-citations
venue: NeurIPS
year: 2019
---

# PyTorch - An Imperative Style, High-Performance Deep Learning Library

## Abstract

Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.

## Paper References

1. [cuDNN - Efficient Primitives for Deep Learning](2014-cudnn-efficient-primitives-for-deep-learning.md)
2. [Automatic differentiation in PyTorch](2017-automatic-differentiation-in-pytorch.md)
3. [Theano - A Python framework for fast computation of mathematical expressions](2016-theano-a-python-framework-for-fast-computation-of-mathematical-expressions.md)
4. [Hogwild - A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](2011-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.md)
5. [Caffe - Convolutional Architecture for Fast Feature Embedding](2014-caffe-convolutional-architecture-for-fast-feature-embedding.md)
6. CNTK - Microsoft's Open-Source Deep-Learning Toolkit
7. [Torch7 - A Matlab-like Environment for Machine Learning](2011-torch7-a-matlab-like-environment-for-machine-learning.md)
8. DyNet - The Dynamic Neural Network Toolkit
9. maxDNN - An Efficient Convolution Kernel for Deep Learning with Maxwell GPUs
10. Hoard - a scalable memory allocator for multithreaded applications
11. Modeling, Inference and Optimization With Composable Differentiable Procedures
12. Julia - A Fresh Approach to Numerical Computing
13. Quantifying the performance of garbage collection vs. explicit memory management
14. Chainer - a Next-Generation Open Source Framework for Deep Learning
15. A Scalable Concurrent malloc(3) Implementation for FreeBSD
16. StarCraft II - A New Challenge for Reinforcement Learning
17. EBLearn - Open-Source Energy-Based Learning in C++
18. Automatic differentiation in machine learning - a survey
19. [Fast Algorithms for Convolutional Neural Networks](2016-fast-algorithms-for-convolutional-neural-networks.md)
20. Forward Modeling for Partial Observation Strategy Games - A StarCraft Defogger
21. Data Structures for Statistical Computing in Python
22. Torch - a modular machine learning software library
23. Automatic Differentiation, C++ Templates, and Photogrammetry
24. Automatic differentiation facilitates OF-integration into steering-angle-based road vehicle tracking
25. SciPy - Open Source Scientific Tools for Python
26. An apl machine
